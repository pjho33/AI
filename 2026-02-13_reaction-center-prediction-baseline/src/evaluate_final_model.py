"""
í™•ì¥ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ ìµœì¢… í‰ê°€
"""

import json
from pathlib import Path
import sys

sys.path.append(str(Path(__file__).parent))
from train_stage1_with_data import load_dataset, evaluate_on_dataset, analyze_errors
from stage1_feasibility_predictor import Stage1FeasibilityPredictor


def main():
    """í™•ì¥ëœ ë°ì´í„°ì…‹ìœ¼ë¡œ ìµœì¢… í‰ê°€"""
    
    print("="*70)
    print("Stage 1 ìµœì¢… í‰ê°€ - í™•ì¥ ë°ì´í„°ì…‹")
    print("="*70)
    
    # ë°ì´í„° ë¡œë“œ
    dataset_path = Path(__file__).parent.parent / "data" / "expanded_training_dataset.json"
    dataset = load_dataset(dataset_path)
    
    print(f"\në°ì´í„°ì…‹: {len(dataset)}ê°œ ë°˜ì‘")
    
    # ê¸ì •/ë¶€ì • ë¶„í¬
    positive = sum(1 for d in dataset if d["feasibility_label"])
    negative = len(dataset) - positive
    print(f"  ê¸ì • ì˜ˆì‹œ: {positive}ê°œ ({positive/len(dataset)*100:.1f}%)")
    print(f"  ë¶€ì • ì˜ˆì‹œ: {negative}ê°œ ({negative/len(dataset)*100:.1f}%)")
    
    # ë°˜ì‘ ìœ í˜•ë³„ ë¶„í¬
    reaction_types = {}
    for d in dataset:
        if d["feasibility_label"]:
            rt = d["reaction_type"]
            reaction_types[rt] = reaction_types.get(rt, 0) + 1
    
    print(f"\nê¸ì • ì˜ˆì‹œ ë°˜ì‘ ìœ í˜•:")
    for rt, count in sorted(reaction_types.items()):
        print(f"  {rt}: {count}ê°œ")
    
    # ëª¨ë¸ í‰ê°€
    print("\n" + "="*70)
    print("ëª¨ë¸ í‰ê°€ ì¤‘...")
    print("="*70)
    
    predictor = Stage1FeasibilityPredictor()
    results = evaluate_on_dataset(predictor, dataset)
    
    print("\nì„±ëŠ¥ í‰ê°€ ê²°ê³¼:")
    print("-"*70)
    
    for threshold, metrics in results["performance"].items():
        if threshold.startswith("threshold"):
            print(f"\n{threshold}:")
            for metric, value in metrics.items():
                print(f"  {metric}: {value}")
    
    print(f"\ní‰ê·  ì‹ ë¢°ë„: {results['performance']['average_confidence']}")
    print(f"í‰ê·  P_feasible: {results['performance']['average_P_feasible']}")
    
    # ì˜¤ë¥˜ ë¶„ì„
    print("\n" + "="*70)
    print("ì˜¤ë¥˜ ë¶„ì„ (threshold=0.7)")
    print("="*70)
    
    errors = analyze_errors(
        results["predictions"],
        results["ground_truth"],
        dataset,
        threshold=0.7
    )
    
    print(f"\nFalse Positives: {errors['fp_count']}ê°œ ({errors['fp_count']/negative*100:.1f}%)")
    print(f"False Negatives: {errors['fn_count']}ê°œ ({errors['fn_count']/positive*100:.1f}%)")
    
    # FP íŒ¨í„´
    if errors["false_positives"]:
        fp_reasons = {}
        for fp in errors["false_positives"]:
            reason = fp["reason"]
            fp_reasons[reason] = fp_reasons.get(reason, 0) + 1
        
        print(f"\nFalse Positive ì´ìœ :")
        for reason, count in sorted(fp_reasons.items(), key=lambda x: -x[1]):
            print(f"  {reason}: {count}ê°œ")
    
    # ìµœì  ì„ê³„ê°’
    print("\n" + "="*70)
    print("ìµœì  ì„ê³„ê°’ ë¶„ì„")
    print("="*70)
    
    best_threshold = 0.5
    best_f1 = 0.0
    
    for threshold_key, metrics in results["performance"].items():
        if threshold_key.startswith("threshold"):
            f1 = metrics["f1"]
            threshold = float(threshold_key.split("_")[1])
            if f1 > best_f1:
                best_f1 = f1
                best_threshold = threshold
    
    print(f"\nìµœì  ì„ê³„ê°’: {best_threshold}")
    print(f"ìµœê³  F1 ì ìˆ˜: {best_f1:.3f}")
    
    # ìµœì¢… ìš”ì•½
    print("\n" + "="*70)
    print("ìµœì¢… ìš”ì•½")
    print("="*70)
    
    print(f"\në°ì´í„°ì…‹: {len(dataset)}ê°œ ë°˜ì‘")
    print(f"  ê¸ì •: {positive}ê°œ")
    print(f"  ë¶€ì •: {negative}ê°œ")
    
    print(f"\nìµœê³  ì„±ëŠ¥:")
    print(f"  ì„ê³„ê°’: {best_threshold}")
    print(f"  F1 ì ìˆ˜: {best_f1:.3f}")
    print(f"  Accuracy: {results['performance'][f'threshold_{best_threshold}']['accuracy']:.3f}")
    print(f"  Precision: {results['performance'][f'threshold_{best_threshold}']['precision']:.3f}")
    print(f"  Recall: {results['performance'][f'threshold_{best_threshold}']['recall']:.3f}")
    
    print(f"\nì˜¤ë¥˜:")
    print(f"  False Positives: {errors['fp_count']}ê°œ")
    print(f"  False Negatives: {errors['fn_count']}ê°œ")
    
    print("\n" + "="*70)
    print("Stage 1 ì™„ë£Œ!")
    print("="*70)
    
    print("\nâœ… ë‹¬ì„±í•œ ê²ƒ:")
    print("  â€¢ í™”í•™ì  ê°€ëŠ¥ì„± ì˜ˆì¸¡ ì‹œìŠ¤í…œ")
    print("  â€¢ ë°˜ì‘ ì¤‘ì‹¬ ì˜ˆì¸¡")
    print("  â€¢ ì œí•œ ìš”ì¸ ì‹ë³„")
    print("  â€¢ ì‹ ë¢°ë„ ì •ëŸ‰í™”")
    print(f"  â€¢ F1 ì ìˆ˜: {best_f1:.3f}")
    
    print("\nğŸ“Š í•™ìŠµ ë°ì´í„°:")
    print(f"  â€¢ {len(dataset)}ê°œ ë°˜ì‘")
    print(f"  â€¢ ì‚°í™”: {reaction_types.get('oxidation', 0)}ê°œ")
    print(f"  â€¢ ì´ì„±ì§ˆí™”: {reaction_types.get('isomerization', 0)}ê°œ")
    
    print("\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„ (Stage 2):")
    print("  â€¢ ì„±ëŠ¥ ì˜ˆì¸¡ (ìˆ˜ìœ¨, kcat, Km)")
    print("  â€¢ ê²°ì¸¡ ë°ì´í„° ëŒ€ì‘")
    print("  â€¢ ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”")


if __name__ == "__main__":
    main()
